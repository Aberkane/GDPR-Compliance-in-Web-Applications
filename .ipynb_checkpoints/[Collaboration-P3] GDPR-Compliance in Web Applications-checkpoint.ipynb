{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing GDPR-Compliance in Web Applications: A Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assess the GDPR-compliance of web applications based on their privacy policies. We use a classification model, trained on a corpus of 18,397 natural sentences, to classify the privacy policies on whether five General Data Protection Regulation (GDPR) privacy policy core requirements are communicated in the policy.\n",
    "\n",
    "__Relevance:__ The GDPR applies to any personal data processing of EU citizens. We aim to assess the state of GDPR-compliance in application software based on their privacy policies.\n",
    "\n",
    "__Focus:__ web applications; as the web application paradigm is widely used due to the omnipresence of web browsers across PCs and mobile devices. In particular, we focus on organisations that provide cloud-based solutions: Cloud Computing, Cloud Data Services, Cloud Infrastructure, Cloud, Management, and Cloud Storage.\n",
    "\n",
    "\n",
    "__Goal:__ to scrutinize the privacy policies of web applications using ML, to assess whether core privacy policy requirements are communicated.\n",
    "\n",
    "#### __RQ:__ What is the state of GDPR-compliance disclosure in web applications?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: collect list of companies active in the Web Apps industry\n",
    "\n",
    "To do so we utilize the Crunchbase database that allows us to identify companies that provide webbased services, filtered on location (which in our case will be the European Union). We used \n",
    "\n",
    "We've imported 2792 companies using the following criteria:\n",
    "- Industry: Web Services -> Cloud Computing, Cloud Data Services, Cloud Infrastructure, Cloud, Management, and Cloud Storage\n",
    "- Location: USA, India, EU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "from six.moves.urllib.parse import urlparse\n",
    "import urllib\n",
    "import sys\n",
    "import time\n",
    "import nltk\n",
    "import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "import random\n",
    "# from googlesearch import search\n",
    "from langdetect import detect\n",
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\aaberkan\\OneDrive - UGent\\Scripts\\GDPR-Compliance in Web Applications\\data\\Crunchbase\\Cloud'\n",
    "filenames = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len = 30\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>Organization Name URL</th>\n",
       "      <th>Full Description</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Website</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>CB Rank (Company)</th>\n",
       "      <th>SEMrush - Monthly Visits</th>\n",
       "      <th>SEMrush - Average Visits (6 months)</th>\n",
       "      <th>...</th>\n",
       "      <th>Founded Date</th>\n",
       "      <th>Founded Date Precision</th>\n",
       "      <th>Number of Founders</th>\n",
       "      <th>Number of Employees</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Apptopia - Number of Apps</th>\n",
       "      <th>Apptopia - Downloads Last 30 Days</th>\n",
       "      <th>Aberdeen - IT Spend</th>\n",
       "      <th>Aberdeen - IT Spend Currency</th>\n",
       "      <th>Aberdeen - IT Spend Currency (in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ex Libris</td>\n",
       "      <td>https://www.crunchbase.com/organization/ex-libris</td>\n",
       "      <td>Ex Libris Group is a leading provider of libra...</td>\n",
       "      <td>Apps, Cloud Computing, Enterprise Software, In...</td>\n",
       "      <td>http://www.exlibrisgroup.com</td>\n",
       "      <td>Ballerup, Hovedstaden, Denmark</td>\n",
       "      <td>Ex Libris Group is a leading provider of libra...</td>\n",
       "      <td>165,720</td>\n",
       "      <td>13,961,244</td>\n",
       "      <td>14,073,988.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1986-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>2.0</td>\n",
       "      <td>501-1000</td>\n",
       "      <td>Azriel Morag, Evgeniy Larionov</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3,443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exact</td>\n",
       "      <td>https://www.crunchbase.com/organization/exact</td>\n",
       "      <td>Exact is a global supplier of cloud business s...</td>\n",
       "      <td>Accounting, Cloud Computing, CRM, Enterprise R...</td>\n",
       "      <td>http://www.exact.com</td>\n",
       "      <td>Delft, Zuid-Holland, The Netherlands</td>\n",
       "      <td>Exact is a company that provides cloud based b...</td>\n",
       "      <td>229,780</td>\n",
       "      <td>622,387</td>\n",
       "      <td>672,910.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1984-07-23</td>\n",
       "      <td>day</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>Arco Van Nieuwland, Eduard Hagens, Irfan Verdia</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11,294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xperience</td>\n",
       "      <td>https://www.crunchbase.com/organization/xperie...</td>\n",
       "      <td>Xperience provides software solutions within E...</td>\n",
       "      <td>Cloud Computing, Consulting, CRM, Enterprise R...</td>\n",
       "      <td>https://www.xperience-group.com/</td>\n",
       "      <td>Antrim, Antrim, United Kingdom</td>\n",
       "      <td>Xperience provides software solutions within E...</td>\n",
       "      <td>187,002</td>\n",
       "      <td>402,949</td>\n",
       "      <td>198,967.83</td>\n",
       "      <td>...</td>\n",
       "      <td>1969-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101-250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6256711.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>6256711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sage</td>\n",
       "      <td>https://www.crunchbase.com/organization/sage-c1e4</td>\n",
       "      <td>Sage DPW-Software is now implementing over 100...</td>\n",
       "      <td>Cloud Computing, Computer, Private Cloud, Secu...</td>\n",
       "      <td>https://www.sagedpw.at/</td>\n",
       "      <td>Vienna, Wien, Austria</td>\n",
       "      <td>Sage provides software for HR services.</td>\n",
       "      <td>362,734</td>\n",
       "      <td>319,471</td>\n",
       "      <td>219,712.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101-250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novah√©</td>\n",
       "      <td>https://www.crunchbase.com/organization/novah√©</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Computing, Information Technology, IT In...</td>\n",
       "      <td>https://www.novahe.fr/</td>\n",
       "      <td>Orl√©ans, Centre, France</td>\n",
       "      <td>Novah√© is an information technology company sp...</td>\n",
       "      <td>930,723</td>\n",
       "      <td>288,214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51-100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21235</th>\n",
       "      <td>BackupAddict</td>\n",
       "      <td>https://www.crunchbase.com/organization/backup...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Information Technology, Profess...</td>\n",
       "      <td>https://www.backupaddict.com/</td>\n",
       "      <td>Jersey Shore, Pennsylvania, United States</td>\n",
       "      <td>BackupAddict renders online backup plans to pr...</td>\n",
       "      <td>2,145,360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21236</th>\n",
       "      <td>NetConvergence, Inc.</td>\n",
       "      <td>https://www.crunchbase.com/organization/netcon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Enterprise Software, Informatio...</td>\n",
       "      <td>http://www.netconvergence.com</td>\n",
       "      <td>Santa Clara, California, United States</td>\n",
       "      <td>NetConvergence, Inc. is an intellectual proper...</td>\n",
       "      <td>2,215,033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21237</th>\n",
       "      <td>MyLabBook.com</td>\n",
       "      <td>https://www.crunchbase.com/organization/mylabb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Data Services, Cloud Storage, Software</td>\n",
       "      <td>https://www.mylabbook.com</td>\n",
       "      <td>Texas, South Carolina, United States</td>\n",
       "      <td>MyLabBook.com is a company that facilitates op...</td>\n",
       "      <td>2,222,155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21238</th>\n",
       "      <td>Radmedix</td>\n",
       "      <td>https://www.crunchbase.com/organization/radmedix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Manufacturing, Medical Device, ...</td>\n",
       "      <td>https://radmedix.com</td>\n",
       "      <td>Dayton, Ohio, United States</td>\n",
       "      <td>Radmedix is an x-ray manufacturer that provide...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>Knockout PC Repair</td>\n",
       "      <td>https://www.crunchbase.com/organization/knocko...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Information Technology, IT Mana...</td>\n",
       "      <td>https://knockoutpcrepair.com/</td>\n",
       "      <td>Brentwood, California, United States</td>\n",
       "      <td>Knockout PC Repair is an IT company that provi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21240 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Organization Name  \\\n",
       "0                 Ex Libris   \n",
       "1                     Exact   \n",
       "2                 Xperience   \n",
       "3                      Sage   \n",
       "4                    Novah√©   \n",
       "...                     ...   \n",
       "21235          BackupAddict   \n",
       "21236  NetConvergence, Inc.   \n",
       "21237         MyLabBook.com   \n",
       "21238              Radmedix   \n",
       "21239    Knockout PC Repair   \n",
       "\n",
       "                                   Organization Name URL  \\\n",
       "0      https://www.crunchbase.com/organization/ex-libris   \n",
       "1          https://www.crunchbase.com/organization/exact   \n",
       "2      https://www.crunchbase.com/organization/xperie...   \n",
       "3      https://www.crunchbase.com/organization/sage-c1e4   \n",
       "4         https://www.crunchbase.com/organization/novah√©   \n",
       "...                                                  ...   \n",
       "21235  https://www.crunchbase.com/organization/backup...   \n",
       "21236  https://www.crunchbase.com/organization/netcon...   \n",
       "21237  https://www.crunchbase.com/organization/mylabb...   \n",
       "21238   https://www.crunchbase.com/organization/radmedix   \n",
       "21239  https://www.crunchbase.com/organization/knocko...   \n",
       "\n",
       "                                        Full Description  \\\n",
       "0      Ex Libris Group is a leading provider of libra...   \n",
       "1      Exact is a global supplier of cloud business s...   \n",
       "2      Xperience provides software solutions within E...   \n",
       "3      Sage DPW-Software is now implementing over 100...   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "21235                                                NaN   \n",
       "21236                                                NaN   \n",
       "21237                                                NaN   \n",
       "21238                                                NaN   \n",
       "21239                                                NaN   \n",
       "\n",
       "                                              Industries  \\\n",
       "0      Apps, Cloud Computing, Enterprise Software, In...   \n",
       "1      Accounting, Cloud Computing, CRM, Enterprise R...   \n",
       "2      Cloud Computing, Consulting, CRM, Enterprise R...   \n",
       "3      Cloud Computing, Computer, Private Cloud, Secu...   \n",
       "4      Cloud Computing, Information Technology, IT In...   \n",
       "...                                                  ...   \n",
       "21235  Cloud Storage, Information Technology, Profess...   \n",
       "21236  Cloud Storage, Enterprise Software, Informatio...   \n",
       "21237       Cloud Data Services, Cloud Storage, Software   \n",
       "21238  Cloud Storage, Manufacturing, Medical Device, ...   \n",
       "21239  Cloud Storage, Information Technology, IT Mana...   \n",
       "\n",
       "                                Website  \\\n",
       "0          http://www.exlibrisgroup.com   \n",
       "1                  http://www.exact.com   \n",
       "2      https://www.xperience-group.com/   \n",
       "3               https://www.sagedpw.at/   \n",
       "4                https://www.novahe.fr/   \n",
       "...                                 ...   \n",
       "21235     https://www.backupaddict.com/   \n",
       "21236     http://www.netconvergence.com   \n",
       "21237         https://www.mylabbook.com   \n",
       "21238              https://radmedix.com   \n",
       "21239     https://knockoutpcrepair.com/   \n",
       "\n",
       "                           Headquarters Location  \\\n",
       "0                 Ballerup, Hovedstaden, Denmark   \n",
       "1           Delft, Zuid-Holland, The Netherlands   \n",
       "2                 Antrim, Antrim, United Kingdom   \n",
       "3                          Vienna, Wien, Austria   \n",
       "4                        Orl√©ans, Centre, France   \n",
       "...                                          ...   \n",
       "21235  Jersey Shore, Pennsylvania, United States   \n",
       "21236     Santa Clara, California, United States   \n",
       "21237       Texas, South Carolina, United States   \n",
       "21238                Dayton, Ohio, United States   \n",
       "21239       Brentwood, California, United States   \n",
       "\n",
       "                                             Description CB Rank (Company)  \\\n",
       "0      Ex Libris Group is a leading provider of libra...           165,720   \n",
       "1      Exact is a company that provides cloud based b...           229,780   \n",
       "2      Xperience provides software solutions within E...           187,002   \n",
       "3                Sage provides software for HR services.           362,734   \n",
       "4      Novah√© is an information technology company sp...           930,723   \n",
       "...                                                  ...               ...   \n",
       "21235  BackupAddict renders online backup plans to pr...         2,145,360   \n",
       "21236  NetConvergence, Inc. is an intellectual proper...         2,215,033   \n",
       "21237  MyLabBook.com is a company that facilitates op...         2,222,155   \n",
       "21238  Radmedix is an x-ray manufacturer that provide...               NaN   \n",
       "21239  Knockout PC Repair is an IT company that provi...               NaN   \n",
       "\n",
       "      SEMrush - Monthly Visits SEMrush - Average Visits (6 months)  ...  \\\n",
       "0                   13,961,244                        14,073,988.5  ...   \n",
       "1                      622,387                           672,910.5  ...   \n",
       "2                      402,949                          198,967.83  ...   \n",
       "3                      319,471                          219,712.33  ...   \n",
       "4                      288,214                                 NaN  ...   \n",
       "...                        ...                                 ...  ...   \n",
       "21235                      NaN                                 NaN  ...   \n",
       "21236                      NaN                                 NaN  ...   \n",
       "21237                      NaN                                 NaN  ...   \n",
       "21238                      NaN                                 NaN  ...   \n",
       "21239                      NaN                                 NaN  ...   \n",
       "\n",
       "      Founded Date Founded Date Precision Number of Founders  \\\n",
       "0       1986-01-01                   year                2.0   \n",
       "1       1984-07-23                    day                3.0   \n",
       "2       1969-01-01                   year                NaN   \n",
       "3       1972-01-01                   year                NaN   \n",
       "4       1986-06-30                    day                NaN   \n",
       "...            ...                    ...                ...   \n",
       "21235          NaN                    NaN                NaN   \n",
       "21236          NaN                    NaN                NaN   \n",
       "21237   1994-01-01                   year                NaN   \n",
       "21238          NaN                    NaN                NaN   \n",
       "21239   2002-01-01                   year                NaN   \n",
       "\n",
       "       Number of Employees                                         Founders  \\\n",
       "0                 501-1000                   Azriel Morag, Evgeniy Larionov   \n",
       "1                1001-5000  Arco Van Nieuwland, Eduard Hagens, Irfan Verdia   \n",
       "2                  101-250                                              NaN   \n",
       "3                  101-250                                              NaN   \n",
       "4                   51-100                                              NaN   \n",
       "...                    ...                                              ...   \n",
       "21235                11-50                                              NaN   \n",
       "21236                  NaN                                              NaN   \n",
       "21237                 1-10                                              NaN   \n",
       "21238                11-50                                              NaN   \n",
       "21239                11-50                                              NaN   \n",
       "\n",
       "      Apptopia - Number of Apps Apptopia - Downloads Last 30 Days  \\\n",
       "0                          19.0                             3,443   \n",
       "1                          32.0                            11,294   \n",
       "2                           NaN                               NaN   \n",
       "3                           NaN                               NaN   \n",
       "4                           NaN                               NaN   \n",
       "...                         ...                               ...   \n",
       "21235                       NaN                               NaN   \n",
       "21236                       NaN                               NaN   \n",
       "21237                       NaN                               NaN   \n",
       "21238                       NaN                               NaN   \n",
       "21239                       NaN                               NaN   \n",
       "\n",
       "      Aberdeen - IT Spend Aberdeen - IT Spend Currency  \\\n",
       "0                     NaN                          NaN   \n",
       "1                     NaN                          NaN   \n",
       "2               6256711.0                          USD   \n",
       "3                     NaN                          NaN   \n",
       "4                     NaN                          NaN   \n",
       "...                   ...                          ...   \n",
       "21235                 NaN                          NaN   \n",
       "21236                 NaN                          NaN   \n",
       "21237                 NaN                          NaN   \n",
       "21238                 NaN                          NaN   \n",
       "21239                 NaN                          NaN   \n",
       "\n",
       "      Aberdeen - IT Spend Currency (in USD)  \n",
       "0                                       NaN  \n",
       "1                                       NaN  \n",
       "2                                 6256711.0  \n",
       "3                                       NaN  \n",
       "4                                       NaN  \n",
       "...                                     ...  \n",
       "21235                                   NaN  \n",
       "21236                                   NaN  \n",
       "21237                                   NaN  \n",
       "21238                                   NaN  \n",
       "21239                                   NaN  \n",
       "\n",
       "[21240 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crunch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "crunch_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data = crunch_data[((10267 + 1) + 4244):].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>Organization Name URL</th>\n",
       "      <th>Full Description</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Website</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>CB Rank (Company)</th>\n",
       "      <th>SEMrush - Monthly Visits</th>\n",
       "      <th>SEMrush - Average Visits (6 months)</th>\n",
       "      <th>...</th>\n",
       "      <th>Founded Date</th>\n",
       "      <th>Founded Date Precision</th>\n",
       "      <th>Number of Founders</th>\n",
       "      <th>Number of Employees</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Apptopia - Number of Apps</th>\n",
       "      <th>Apptopia - Downloads Last 30 Days</th>\n",
       "      <th>Aberdeen - IT Spend</th>\n",
       "      <th>Aberdeen - IT Spend Currency</th>\n",
       "      <th>Aberdeen - IT Spend Currency (in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16663</th>\n",
       "      <td>Polyaxon</td>\n",
       "      <td>https://www.crunchbase.com/organization/polyaxon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artificial Intelligence, Cloud Infrastructure,...</td>\n",
       "      <td>https://polyaxon.com</td>\n",
       "      <td>Berlin, Berlin, Germany</td>\n",
       "      <td>An open source platform for reproducible machi...</td>\n",
       "      <td>208,230</td>\n",
       "      <td>2,642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16664</th>\n",
       "      <td>Mainstream</td>\n",
       "      <td>https://www.crunchbase.com/organization/mainst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Infrastructure, Information Technology, ...</td>\n",
       "      <td>https://www.mainstream.rs</td>\n",
       "      <td>Belgrade, Vojvodina, Serbia</td>\n",
       "      <td>Mainstream provides advanced cloud, managed ho...</td>\n",
       "      <td>439,301</td>\n",
       "      <td>2,639</td>\n",
       "      <td>1,560.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51-100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16666</th>\n",
       "      <td>Replex</td>\n",
       "      <td>https://www.crunchbase.com/organization/replex...</td>\n",
       "      <td>Replex is the first governance and cost manage...</td>\n",
       "      <td>Cloud Infrastructure, Cloud Management, Inform...</td>\n",
       "      <td>https://www.replex.io</td>\n",
       "      <td>Leipzig, Sachsen, Germany</td>\n",
       "      <td>Replex provides software solutions.</td>\n",
       "      <td>26,882</td>\n",
       "      <td>2,439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>month</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11-50</td>\n",
       "      <td>Christian Falk, Costantino Lattarulo, Dennis J...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16667</th>\n",
       "      <td>Power DCloud</td>\n",
       "      <td>https://www.crunchbase.com/organization/power-...</td>\n",
       "      <td>Power Ecosystem is a web3 company, developer o...</td>\n",
       "      <td>Blockchain, Cloud Infrastructure, Cloud Storag...</td>\n",
       "      <td>https://thepower.io</td>\n",
       "      <td>Tallinn, Harjumaa, Estonia</td>\n",
       "      <td>DCloud is a nextgen web3 all-in-one decentrali...</td>\n",
       "      <td>142,924</td>\n",
       "      <td>2,227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>month</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11-50</td>\n",
       "      <td>Dmitry Burov, Igor Belousov, Max Mikhailenko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16669</th>\n",
       "      <td>Red Kubes</td>\n",
       "      <td>https://www.crunchbase.com/organization/red-kubes</td>\n",
       "      <td>For all that Kubernetes can do, it still requi...</td>\n",
       "      <td>Cloud Infrastructure, Software</td>\n",
       "      <td>https://redkubes.com/</td>\n",
       "      <td>Utrecht, Utrecht, The Netherlands</td>\n",
       "      <td>Red Kubes is a Dutch start-up founded in 2019 ...</td>\n",
       "      <td>74,886</td>\n",
       "      <td>2,174</td>\n",
       "      <td>1,725.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>day</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11-50</td>\n",
       "      <td>Maurice Faber, Sander Rodenhuis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21234</th>\n",
       "      <td>Affordable Cloud Hosting</td>\n",
       "      <td>https://www.crunchbase.com/organization/afford...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Information Technology, Web Hos...</td>\n",
       "      <td>http://www.affordablecloudhosting.com</td>\n",
       "      <td>Tampa, Florida, United States</td>\n",
       "      <td>Affordable Cloud Hosting is a company that pro...</td>\n",
       "      <td>2,116,766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269653.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>269653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21235</th>\n",
       "      <td>BackupAddict</td>\n",
       "      <td>https://www.crunchbase.com/organization/backup...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Information Technology, Profess...</td>\n",
       "      <td>https://www.backupaddict.com/</td>\n",
       "      <td>Jersey Shore, Pennsylvania, United States</td>\n",
       "      <td>BackupAddict renders online backup plans to pr...</td>\n",
       "      <td>2,145,360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21236</th>\n",
       "      <td>NetConvergence, Inc.</td>\n",
       "      <td>https://www.crunchbase.com/organization/netcon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Enterprise Software, Informatio...</td>\n",
       "      <td>http://www.netconvergence.com</td>\n",
       "      <td>Santa Clara, California, United States</td>\n",
       "      <td>NetConvergence, Inc. is an intellectual proper...</td>\n",
       "      <td>2,215,033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21238</th>\n",
       "      <td>Radmedix</td>\n",
       "      <td>https://www.crunchbase.com/organization/radmedix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Manufacturing, Medical Device, ...</td>\n",
       "      <td>https://radmedix.com</td>\n",
       "      <td>Dayton, Ohio, United States</td>\n",
       "      <td>Radmedix is an x-ray manufacturer that provide...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>Knockout PC Repair</td>\n",
       "      <td>https://www.crunchbase.com/organization/knocko...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud Storage, Information Technology, IT Mana...</td>\n",
       "      <td>https://knockoutpcrepair.com/</td>\n",
       "      <td>Brentwood, California, United States</td>\n",
       "      <td>Knockout PC Repair is an IT company that provi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3371 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Organization Name  \\\n",
       "16663                  Polyaxon   \n",
       "16664                Mainstream   \n",
       "16666                    Replex   \n",
       "16667              Power DCloud   \n",
       "16669                 Red Kubes   \n",
       "...                         ...   \n",
       "21234  Affordable Cloud Hosting   \n",
       "21235              BackupAddict   \n",
       "21236      NetConvergence, Inc.   \n",
       "21238                  Radmedix   \n",
       "21239        Knockout PC Repair   \n",
       "\n",
       "                                   Organization Name URL  \\\n",
       "16663   https://www.crunchbase.com/organization/polyaxon   \n",
       "16664  https://www.crunchbase.com/organization/mainst...   \n",
       "16666  https://www.crunchbase.com/organization/replex...   \n",
       "16667  https://www.crunchbase.com/organization/power-...   \n",
       "16669  https://www.crunchbase.com/organization/red-kubes   \n",
       "...                                                  ...   \n",
       "21234  https://www.crunchbase.com/organization/afford...   \n",
       "21235  https://www.crunchbase.com/organization/backup...   \n",
       "21236  https://www.crunchbase.com/organization/netcon...   \n",
       "21238   https://www.crunchbase.com/organization/radmedix   \n",
       "21239  https://www.crunchbase.com/organization/knocko...   \n",
       "\n",
       "                                        Full Description  \\\n",
       "16663                                                NaN   \n",
       "16664                                                NaN   \n",
       "16666  Replex is the first governance and cost manage...   \n",
       "16667  Power Ecosystem is a web3 company, developer o...   \n",
       "16669  For all that Kubernetes can do, it still requi...   \n",
       "...                                                  ...   \n",
       "21234                                                NaN   \n",
       "21235                                                NaN   \n",
       "21236                                                NaN   \n",
       "21238                                                NaN   \n",
       "21239                                                NaN   \n",
       "\n",
       "                                              Industries  \\\n",
       "16663  Artificial Intelligence, Cloud Infrastructure,...   \n",
       "16664  Cloud Infrastructure, Information Technology, ...   \n",
       "16666  Cloud Infrastructure, Cloud Management, Inform...   \n",
       "16667  Blockchain, Cloud Infrastructure, Cloud Storag...   \n",
       "16669                     Cloud Infrastructure, Software   \n",
       "...                                                  ...   \n",
       "21234  Cloud Storage, Information Technology, Web Hos...   \n",
       "21235  Cloud Storage, Information Technology, Profess...   \n",
       "21236  Cloud Storage, Enterprise Software, Informatio...   \n",
       "21238  Cloud Storage, Manufacturing, Medical Device, ...   \n",
       "21239  Cloud Storage, Information Technology, IT Mana...   \n",
       "\n",
       "                                     Website  \\\n",
       "16663                   https://polyaxon.com   \n",
       "16664              https://www.mainstream.rs   \n",
       "16666                  https://www.replex.io   \n",
       "16667                    https://thepower.io   \n",
       "16669                  https://redkubes.com/   \n",
       "...                                      ...   \n",
       "21234  http://www.affordablecloudhosting.com   \n",
       "21235          https://www.backupaddict.com/   \n",
       "21236          http://www.netconvergence.com   \n",
       "21238                   https://radmedix.com   \n",
       "21239          https://knockoutpcrepair.com/   \n",
       "\n",
       "                           Headquarters Location  \\\n",
       "16663                    Berlin, Berlin, Germany   \n",
       "16664                Belgrade, Vojvodina, Serbia   \n",
       "16666                  Leipzig, Sachsen, Germany   \n",
       "16667                 Tallinn, Harjumaa, Estonia   \n",
       "16669          Utrecht, Utrecht, The Netherlands   \n",
       "...                                          ...   \n",
       "21234              Tampa, Florida, United States   \n",
       "21235  Jersey Shore, Pennsylvania, United States   \n",
       "21236     Santa Clara, California, United States   \n",
       "21238                Dayton, Ohio, United States   \n",
       "21239       Brentwood, California, United States   \n",
       "\n",
       "                                             Description CB Rank (Company)  \\\n",
       "16663  An open source platform for reproducible machi...           208,230   \n",
       "16664  Mainstream provides advanced cloud, managed ho...           439,301   \n",
       "16666                Replex provides software solutions.            26,882   \n",
       "16667  DCloud is a nextgen web3 all-in-one decentrali...           142,924   \n",
       "16669  Red Kubes is a Dutch start-up founded in 2019 ...            74,886   \n",
       "...                                                  ...               ...   \n",
       "21234  Affordable Cloud Hosting is a company that pro...         2,116,766   \n",
       "21235  BackupAddict renders online backup plans to pr...         2,145,360   \n",
       "21236  NetConvergence, Inc. is an intellectual proper...         2,215,033   \n",
       "21238  Radmedix is an x-ray manufacturer that provide...               NaN   \n",
       "21239  Knockout PC Repair is an IT company that provi...               NaN   \n",
       "\n",
       "      SEMrush - Monthly Visits SEMrush - Average Visits (6 months)  ...  \\\n",
       "16663                    2,642                                 NaN  ...   \n",
       "16664                    2,639                            1,560.17  ...   \n",
       "16666                    2,439                                 NaN  ...   \n",
       "16667                    2,227                                 NaN  ...   \n",
       "16669                    2,174                            1,725.67  ...   \n",
       "...                        ...                                 ...  ...   \n",
       "21234                      NaN                                 NaN  ...   \n",
       "21235                      NaN                                 NaN  ...   \n",
       "21236                      NaN                                 NaN  ...   \n",
       "21238                      NaN                                 NaN  ...   \n",
       "21239                      NaN                                 NaN  ...   \n",
       "\n",
       "      Founded Date Founded Date Precision Number of Founders  \\\n",
       "16663   2018-10-01                  month                NaN   \n",
       "16664   2005-01-01                   year                NaN   \n",
       "16666   2016-02-01                  month                5.0   \n",
       "16667   2017-06-01                  month                3.0   \n",
       "16669   2019-07-18                    day                2.0   \n",
       "...            ...                    ...                ...   \n",
       "21234   1993-01-01                   year                NaN   \n",
       "21235          NaN                    NaN                NaN   \n",
       "21236          NaN                    NaN                NaN   \n",
       "21238          NaN                    NaN                NaN   \n",
       "21239   2002-01-01                   year                NaN   \n",
       "\n",
       "       Number of Employees                                           Founders  \\\n",
       "16663                  NaN                                                NaN   \n",
       "16664               51-100                                                NaN   \n",
       "16666                11-50  Christian Falk, Costantino Lattarulo, Dennis J...   \n",
       "16667                11-50       Dmitry Burov, Igor Belousov, Max Mikhailenko   \n",
       "16669                11-50                    Maurice Faber, Sander Rodenhuis   \n",
       "...                    ...                                                ...   \n",
       "21234                  NaN                                                NaN   \n",
       "21235                11-50                                                NaN   \n",
       "21236                  NaN                                                NaN   \n",
       "21238                11-50                                                NaN   \n",
       "21239                11-50                                                NaN   \n",
       "\n",
       "      Apptopia - Number of Apps Apptopia - Downloads Last 30 Days  \\\n",
       "16663                       NaN                               NaN   \n",
       "16664                       NaN                               NaN   \n",
       "16666                       5.0                               NaN   \n",
       "16667                       NaN                               NaN   \n",
       "16669                       NaN                               NaN   \n",
       "...                         ...                               ...   \n",
       "21234                       NaN                               NaN   \n",
       "21235                       NaN                               NaN   \n",
       "21236                       NaN                               NaN   \n",
       "21238                       NaN                               NaN   \n",
       "21239                       NaN                               NaN   \n",
       "\n",
       "      Aberdeen - IT Spend Aberdeen - IT Spend Currency  \\\n",
       "16663                 NaN                          NaN   \n",
       "16664                 NaN                          NaN   \n",
       "16666                 NaN                          NaN   \n",
       "16667                 NaN                          NaN   \n",
       "16669                 NaN                          NaN   \n",
       "...                   ...                          ...   \n",
       "21234            269653.0                          USD   \n",
       "21235                 NaN                          NaN   \n",
       "21236                 NaN                          NaN   \n",
       "21238                 NaN                          NaN   \n",
       "21239                 NaN                          NaN   \n",
       "\n",
       "      Aberdeen - IT Spend Currency (in USD)  \n",
       "16663                                   NaN  \n",
       "16664                                   NaN  \n",
       "16666                                   NaN  \n",
       "16667                                   NaN  \n",
       "16669                                   NaN  \n",
       "...                                     ...  \n",
       "21234                              269653.0  \n",
       "21235                                   NaN  \n",
       "21236                                   NaN  \n",
       "21238                                   NaN  \n",
       "21239                                   NaN  \n",
       "\n",
       "[3371 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crunch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data.to_csv(\"crunch_cloud_conc_p3.csv\", sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean websites list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites_list = crunch_data[\"Website\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3371"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(websites_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove / from the end of the string that contains the website\n",
    "# websites_list = [website.rstrip(website[-1]) if (website[-1] == \"/\") else website for website in websites_list]\n",
    "websites_list = [website.rstrip(website[-1]) if (isinstance(website, str) and website[-1] == \"/\") else website for website in websites_list]\n",
    "# een keer extra voor het geval er een url was met // op het eind\n",
    "websites_list = [website.rstrip(website[-1]) if (isinstance(website, str) and website[-1] == \"/\") else website for website in websites_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(websites_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: scrape privacy policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_privacy_policy_url(query):\n",
    "    keyword_in_title = 0\n",
    "    attempts = 0\n",
    "    url = \"\"\n",
    "    print(\"Query: \" + query)\n",
    "    \n",
    "    try:\n",
    "        query_results_list = return_google_results(query, 3, 5)\n",
    "        print(\"Considering \" + str(len(query_results_list)) + \" URL(s) ...\")\n",
    "        for i, url in enumerate(query_results_list):\n",
    "            term_in_url = 0\n",
    "            attempts = attempts + 1\n",
    "            print(\"Assessing privacy policy URL: \" + url)\n",
    "            \n",
    "            if (re.findall('privacy', url) or re.findall('policy', url) or re.findall('gdpr', url) \n",
    "                or re.findall('terms', url) or re.findall('legal', url)): \n",
    "                print(\"Found relevant terms in URL! Succesful break!\")\n",
    "                break\n",
    "\n",
    "#                     pass\n",
    "            if keyword_in_title == 1 or attempts == 3 or i==(len(query_results_list)-1): \n",
    "                keyword_in_title = 0\n",
    "                attempts = 0\n",
    "                print(\"No results. Breaking ..\")\n",
    "                url = \"\"\n",
    "#                 print(sentences)\n",
    "                break   \n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_google_results(keywords, num_results, attempts):\n",
    "    user_agent_list = [\n",
    "      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "      'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "    ]\n",
    "\n",
    "    html_keywords = urllib.parse.quote_plus(keywords)\n",
    "    sleep_init = 10\n",
    "    \n",
    "    url = \"https://www.google.com/search?q=\" + html_keywords + \"&num=\" + str(num_results)\n",
    "    print(\"** Search query in URL: \" + url)\n",
    "\n",
    "    headers = {'User-Agent': random.choice(user_agent_list)}\n",
    "    \n",
    "    html = requests.get(url, headers=headers)\n",
    "\n",
    "    if html.status_code == 429:\n",
    "        if(attempts == 0):\n",
    "            sys.exit(\"Too many request 429, attempted \"+ str(5)+ \" times, break ...\")\n",
    "        else:\n",
    "            if 'Retry_After' in html.headers:\n",
    "                print(\"Helaas, geen retry-after info\")\n",
    "            else:\n",
    "                time.sleep(sleep_init)\n",
    "                print(\"Too many requests (attempt \"+ str(5 - attempts)+ \"), we will attempt again in \" + str(sleep_init) + \" seconds\")\n",
    "                return_google_results(keywords, num_results, (attempts - 1))\n",
    "    else: \n",
    "        pass\n",
    "        \n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "    allData = soup.find_all(\"div\",{\"class\":\"g\"})\n",
    "\n",
    "    link_list = []\n",
    "    print(\"len alldata: \" + str(len(allData)))\n",
    "    \n",
    "    for i in range(0,len(allData)):\n",
    "        link = allData[i].find('a').get('href')\n",
    "        \n",
    "        if(link is not None):\n",
    "            if(link.find('https') != -1 and link.find('http') == 0 and link.find('aclk') == -1):\n",
    "                print(link)\n",
    "                link_list.append(link)\n",
    "    print(link_list)\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect privacy policy URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_policies_url_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop through each company URL and attempt to find the URL of the privacy policy\n",
    "count_urls = 0\n",
    "for i, url_company in enumerate(websites_list):    \n",
    "    print(i)\n",
    "\n",
    "#     print(len(privacy_policies_url_list))\n",
    "    if(isinstance(\"url_company\", str) is False or (url_company == url_company) is False):\n",
    "        privacy_policies_url_list.append(\"\")\n",
    "    else:\n",
    "        query = \"site:\\\"\" + url_company + \" \\\"privacy policy\"\n",
    "        privacy_policies_url_list.append(get_privacy_policy_url(query))\n",
    "        if(len(privacy_policies_url_list[-1]) > 0):\n",
    "            count_urls = count_urls + 1\n",
    "    print(\"URL count: \" + str(count_urls))\n",
    "    print()\n",
    "    time.sleep(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_policies_url_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(privacy_policies_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len([(collected_url) for collected_url in privacy_policies_url_list if collected_url is not \"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crunch_data[0:7243])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_survived = crunch_data[0:7243].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_survived['PP URL'] = privacy_policies_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "crunch_data_survived.to_csv(\"crunch_data_cloud_surv.csv\", sep='\\t', header=True, index=True, index_label=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r = pd.read_csv(\"crunch_data_cloud_surv.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Scrape privacy policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_policies_google(url):\n",
    "    policies = []\n",
    "    sentences = []    \n",
    "    try:\n",
    "        \n",
    "        article = Article(url)\n",
    "#             print(url)\n",
    "        article.download() #Downloads the link‚Äôs HTML content\n",
    "#             print(url)\n",
    "        article.parse() #Parse the article\n",
    "#             print(url)\n",
    "#                 print(article.title)\n",
    "        doc = nlp(article.text)\n",
    "        print(\"PP language = EN?: \" + str(detect(article.text) == 'en'))\n",
    "        print(\"PP length > 10 sentences?: \" + str(len(list(doc.sents)) > 10))\n",
    "\n",
    "        if detect(article.text) == 'en' and len(list(doc.sents)) > 10:\n",
    "            print(\"Policy meets requirements of language and length ... \")\n",
    "            sentences = list(doc.sents)\n",
    "            print(\"Scraping successful!\")\n",
    "\n",
    "        else:\n",
    "            print(\"Scraping not successful\")\n",
    "    except:\n",
    "            pass\n",
    "    print()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_list_sentences = []\n",
    "for i, pp_url in enumerate(privacy_policies_url_list):\n",
    "    print(i)\n",
    "    if pp_url == \"\":\n",
    "        pp_list_sentences.append(\"\")\n",
    "    else:\n",
    "        pp_list_sentences.append(scrape_policies_google(pp_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(len(pp)) for pp in pp_list_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDPR_classes = ['DPO', 'Purpose', 'Acquired data', 'Data sharing', 'Rights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.014130434782608696, 0.035326086956521736, 0.017934782608695653, 0.03369565217391304, 0.009782608695652175]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(pps):\n",
    "#     tokenizer = nlp.tokenizer\n",
    "    # tokenize sentences\n",
    "    tokenized_sent = [sent.text.split() for sent in pps]\n",
    "    \n",
    "    # remove punctuation\n",
    "    tokenized_sent = [[re.sub('[,‚Äô\\'\\.!?&‚Äú‚Äù():*_;\"]', '', y) for y in x] for x in tokenized_sent]\n",
    "    \n",
    "    # remove words with numbers in them\n",
    "    tokenized_sent = [[y for y in x if not any(c.isdigit() for c in y)] for x in tokenized_sent]\n",
    "    \n",
    "    # remove stopwords   \n",
    "    tokenized_sent_clean = tokenized_sent\n",
    "#     tokenized_sent_clean = [[y for y in x if y not in stopwords.words('english')] for x in tokenized_sent]\n",
    "    \n",
    "    # from nltk.stem import PorterStemmer\n",
    "    porter = PorterStemmer()\n",
    "    tokenized_sent_clean = [[porter.stem(y) for y in x] for x in tokenized_sent_clean]\n",
    "    \n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     tokenized_sent_clean = [[lemmatizer.lemmatize(y) for y in x] for x in tokenized_sent_clean]\n",
    "\n",
    "    \n",
    "    detokenized_pps = []\n",
    "    for i in range(len(tokenized_sent_clean)):\n",
    "        t = ' '.join(tokenized_sent_clean[i])\n",
    "        detokenized_pps.append(t) \n",
    "    \n",
    "    return detokenized_pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_GDPR_columns(df):\n",
    "    df['DPO'] = 0\n",
    "    df['Purpose'] = 0\n",
    "    df['Acquired data'] = 0\n",
    "    df['Data sharing']  = 0\n",
    "    df['Rights'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_GDPR_columns(crunch_data_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_list_sentences_prep = []\n",
    "\n",
    "for j, pp in enumerate(pp_list_sentences):\n",
    "    pp_list_sentences_prep.append(preprocessing(pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_list_sentences_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r['PP text'] = pp_list_sentences_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r.to_csv(\"crunch_data_pp_url_text.csv\", sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r = pd.read_csv(\"crunch_data_pp_url_text.csv\", sep='\\t', encoding='utf-8', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r_selected = crunch_data_r.loc[crunch_data_r['PP text'] != \"[]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in crunch_data_r_selected.iterrows(): \n",
    "    x = row[\"PP text\"]\n",
    "    pp_text_split = x.split(', ')\n",
    "    \n",
    "    for j, category in enumerate(GDPR_classes):\n",
    "             # Load from file to check if everything is ok\n",
    "        filen = \"linreg-oversampling-\" + category + \".pkl\"      \n",
    "        with open(filen, 'rb') as file:\n",
    "            vectorizer, lr = pickle.load(file)\n",
    "            x = vectorizer.transform(pp_text_split)\n",
    "        \n",
    "            y_pred = lr.predict(x)\n",
    "#             print(y_pred)\n",
    "            n_pos_pred = list(y_pred).count(1)\n",
    "#             print(n_pos_pred)\n",
    "            \n",
    "            \n",
    "#             print(\"(\" + str(n_pos_pred) + \"/\" + str(len(pp_text_split)) + \") >= \" + str(thresholds[j]))\n",
    "            if (n_pos_pred/len(pp_text_split)) >= thresholds[j]:\n",
    "    #           MARK THE LABEL AS POSITIVE (1), DEFAULT STATE IS NEGATIVE (0)\n",
    "#                 print(\"TRUE\")\n",
    "                crunch_data_r_selected.at[index, GDPR_classes[j]] = 1\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch_data_r_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Analysis (425 privacy policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, GDPR_class in enumerate(GDPR_classes):\n",
    "    print(GDPR_class)\n",
    "    print(\"Positively classified:\" + str(crunch_data_r_selected[GDPR_class].value_counts()[0]) + \" (\" + str((crunch_data_r_selected[GDPR_class].value_counts()[0]/crunch_data_r_selected.shape[0])*100) + \"%)\")\n",
    "    print(\"Negatively classified:\" + str(crunch_data_r_selected[GDPR_class].value_counts()[1]) + \" (\" + str((crunch_data_r_selected[GDPR_class].value_counts()[1]/crunch_data_r_selected.shape[0])*100) + \"%)\")\n",
    "    classification_analysis = [\n",
    "       [GDPR_class, crunch_data_r_selected.shape[0], crunch_data_r_selected[GDPR_class].value_counts()[0], crunch_data_r_selected[GDPR_class].value_counts()[1]],\n",
    "#        [GDPR_labels[idx], 'L1', 'numerical', 'full data', sm_lr_numpredictors_acc[idx], {k:v for (k,v) in dict(sm_lr_numpredictors[idx].pvalues).items() if ((v <= 0.05) and ( v != 0) and (k != 'const'))}]\n",
    "      ]\n",
    "    classification_analysis = pd.DataFrame(classification_analysis, columns =['GDPR Class', '# companies', 'Postive', 'Negative'])\n",
    "#     print(summary_sm_sk.to_markdown())\n",
    "    \n",
    "    display(HTML(classification_analysis.to_html(index=False)))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select potentially interesting predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Employee (object), \n",
    "- Type (object), \n",
    "- Founded Date (object), \n",
    "- Location\n",
    "- Operating Status (object), \n",
    "- Industry 1 (object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats = crunch_data_r_selected[[\"Employees\", \"Founded Date\", \"Location\", \"Industry 1\", \"DPO\", \"Purpose\", \"Acquired data\", \"Data sharing\", \"Rights\"]].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Employees\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Founded Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Founded Date\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_date = pd_stats[\"Founded Date\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_date_clean = [re.findall(r'(\\d{4})', date)[0] if date is not np.nan else (np.nan) for date in f_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f_date_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Founded Year\"] = f_date_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Founded Year\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Location          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pd_stats[\"Location\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = [(country.split(\", \")[-1]) for country in location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Country\"] = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Industry 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats[\"Industry 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop old columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats.drop(['Founded Date', 'Location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lambda function: categorize_label\n",
    "label_categorical = lambda x: x.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats = pd_stats.apply(label_categorical, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR with Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_stats.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDPR_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd_stats.drop(GDPR_classes,axis=1) # independant features\n",
    "X = pd.get_dummies(X, drop_first = True)\n",
    "sns.clustermap(X.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(pd_stats, test_size=0.2, random_state=42)\n",
    "X_train = train.drop(GDPR_classes,axis=1) # independant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode non-numerical categorical data, and drop first to avoid collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First without PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(pd_stats, test_size=0.25, random_state=25)\n",
    "sel_alpha_list = dict()\n",
    "acc_last = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[GDPR_classes[0]] # dependant variable\n",
    "y_test = test[GDPR_classes[0]] # dependant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent features\n",
    "X_train = train.drop(GDPR_classes, axis=1) \n",
    "# encode non-numerical categorical data, and drop first to avoid collinearity\n",
    "X_train = pd.get_dummies(X_train, drop_first = True)\n",
    "\n",
    "X_test = test.drop(GDPR_classes, axis=1) # independant features\n",
    "X_test = pd.get_dummies(X_test, drop_first = True)\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(y_train,X_train)\n",
    "logit_model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = logit_model.predict(X_train)>=.5\n",
    "pred_test = logit_model.predict(X_test)>=.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = (y_train==pred_train).mean()\n",
    "acc_test = (y_test==pred_test).mean()\n",
    "\n",
    "print(\"Acc: \", acc_test)\n",
    "print(\"Alpha: \", alpha_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = list(np.arange(0.001, 10, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_alpha = optimize_logit(pd_stats, True, alpha_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_logit(pd_stats, reg, alpha_range, intercept_set):\n",
    "    train, test = train_test_split(pd_stats, test_size=0.2, random_state=25)\n",
    "    sel_alpha_list = dict()\n",
    "    acc_last = 0\n",
    "\n",
    "    for GDPR_cat in GDPR_classes:\n",
    "        alpha_sel = alpha_range[0]\n",
    "        acc_last = 0\n",
    "\n",
    "        print(\"***************** NEW ROUND!\")\n",
    "        for alpha_op in alpha_range:\n",
    "            print(\"GDPR-category: \" + GDPR_class)\n",
    "\n",
    "            y_train = train[GDPR_class] # dependant variable\n",
    "            y_test = test[GDPR_class] # dependant variable\n",
    "            \n",
    "#             sys.exit(0)\n",
    "\n",
    "            # independent features\n",
    "            X_train = train.drop(GDPR_classes, axis=1) \n",
    "            # encode non-numerical categorical data, and drop first to avoid collinearity\n",
    "            X_train = pd.get_dummies(X_train, drop_first = True)\n",
    "\n",
    "            X_test = test.drop(GDPR_classes, axis=1) # independant features\n",
    "            X_test = pd.get_dummies(X_test, drop_first = True)\n",
    "\n",
    "            if(intercept_set):\n",
    "                X_train = sm.add_constant(X_train)\n",
    "                X_test = sm.add_constant(X_test)\n",
    "                \n",
    "            print(y_train)\n",
    "\n",
    "            print(\"flag 1\")\n",
    "            model = sm.Logit(y_train,X_train)\n",
    "            print(\"flag 2\")\n",
    "\n",
    "            if(reg):\n",
    "                logit_model = model.fit_regularized(method = 'l1', trim_mode = 'size', alpha = alpha_op)\n",
    "            else:\n",
    "                logit_model = model.fit()\n",
    "\n",
    "            print(\"flag 3\")\n",
    "\n",
    "            pred_train = logit_model.predict(X_train)>=.5\n",
    "\n",
    "            pred_test = logit_model.predict(X_test)>=.5\n",
    "\n",
    "            acc_train = (y_train==pred_train).mean()\n",
    "\n",
    "            acc_test = (y_test==pred_test).mean()\n",
    "            \n",
    "            print(\"Acc: \", acc_test)\n",
    "            print(\"Alpha: \", alpha_op)\n",
    "\n",
    "            sys.exit(0)\n",
    "            if(acc_test >= acc_last):\n",
    "                print(\"Alpha selected!\")\n",
    "                alpha_sel = alpha_op \n",
    "                acc_last = acc_test\n",
    "\n",
    "            # last alpha in range? Place optimized alpha and accuracy in dict\n",
    "            if(alpha_op == alpha_list[-1]):\n",
    "                sel_alpha_list[GDPR_class] = [alpha_sel, acc_last]\n",
    "            \n",
    "            print()\n",
    "            print()\n",
    "\n",
    "    return sel_alpha_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
